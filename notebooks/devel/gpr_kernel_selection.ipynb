{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/multipledispatch-0.4.9-py3.6.egg/multipledispatch/dispatcher.py:24: AmbiguityWarning: \n",
      "Ambiguities exist in dispatched function _expectation\n",
      "\n",
      "The following signatures may result in ambiguous behavior:\n",
      "\t[Gaussian, Linear, NoneType, Sum, InducingPoints], [Gaussian, Identity, NoneType, Kernel, InducingPoints]\n",
      "\n",
      "\n",
      "Consider making the following additions:\n",
      "\n",
      "@dispatch(Gaussian, Identity, NoneType, Sum, InducingPoints)\n",
      "def _expectation(...)\n",
      "  warn(warning_text(dispatcher.name, ambiguities), AmbiguityWarning)\n"
     ]
    }
   ],
   "source": [
    "import gpflow as gp\n",
    "import numpy as np\n",
    "from bayes_tec.datapack import DataPack\n",
    "from bayes_tec.utils.data_utils import make_coord_array\n",
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DataPack('../../scripts/data/killms_datapack_2.hdf5',readonly = True) as datapack:\n",
    "    datapack.switch_solset('sol000')\n",
    "    datapack.select(ant='RS210HBA',time=slice(50,55,1),pol=slice(0,1,1),freq=slice(0,48,20))\n",
    "    phase,axes = datapack.phase\n",
    "    patch_names, directions = datapack.get_sources(axes['dir'])\n",
    "    antenna_labels, antenans = datapack.get_antennas(axes['ant'])\n",
    "    _, freqs = datapack.get_freqs(axes['freq'])\n",
    "    _, times = datapack.get_times(axes['time'])\n",
    "    _, pols = datapack.get_pols(axes['pol'])\n",
    "    \n",
    "X_t = (times.mjd*86400. - times[0].mjd*86400.)[:,None]\n",
    "X_t = (X_t - X_t.mean())/X_t.std()\n",
    "X_d = np.array([directions.ra.deg-directions.ra.deg.mean(), directions.dec.deg-directions.dec.deg.mean()]).T\n",
    "X_d /= X_d.std()\n",
    "\n",
    "X_f = freqs[:,None]\n",
    "\n",
    "X = make_coord_array(X_d, X_f, X_t,flat=True)\n",
    "X_freqs = X[:,[2]]\n",
    "X = X[:,[0,1,3]]\n",
    "\n",
    "Y = phase[0,:,0,:,:].reshape((-1,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano.tensor as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/joblib-0.11-py3.6.egg/joblib/pool.py\", line 362, in get\n",
      "    return recv()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/connection.py\", line 251, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/compile/function_module.py\", line 1082, in _constructor_Function\n",
      "    f = maker.create(input_storage, trustme=True)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/compile/function_module.py\", line 1715, in create\n",
      "    input_storage=input_storage_lists, storage_map=storage_map)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/link.py\", line 699, in make_thunk\n",
      "    storage_map=storage_map)[:3]\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/vm.py\", line 1084, in make_all\n",
      "    impl=impl))\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/op.py\", line 833, in make_c_thunk\n",
      "    e = FunctionGraph(node.inputs, node.outputs)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/fg.py\", line 137, in __init__\n",
      "    inputs, outputs = graph.clone(inputs, outputs)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/graph.py\", line 862, in clone\n",
      "    equiv = clone_get_equiv(i, o, copy_inputs, copy_orphans)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/graph.py\", line 899, in clone_get_equiv\n",
      "    cpy = input.clone()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/graph.py\", line 607, in clone\n",
      "    cp = self.__class__(self.type, self.data, self.name)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/tensor/var.py\", line 961, in __init__\n",
      "    Constant.__init__(self, type, data, name)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/graph.py\", line 579, in __init__\n",
      "    self.data = type.filter(data)\n",
      "TypeError: ('The following error happened while compiling the node', Elemwise{Composite{((i0 * i1) + i2)}}(Elemwise{Composite{exp((i0 * clip(i1, i2, i3)))}}[(0, 1)].0, Elemwise{sqr,no_inplace}.0, TensorConstant{[[1.e-06 0..0 1.e-06]]}), '\\n', 'The numpy.ndarray object is not aligned. Theano C code does not support that.', 'object buffer<memory at 0x7f94e993f2d0>', 'object shape', (675, 675), 'object strides', (5400, 8), 'object dtype', dtype('float64'))\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/tensor/type.py\", line 189, in filter\n",
      "    \"object dtype\", data.dtype)\n",
      "Process ForkPoolWorker-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/joblib-0.11-py3.6.egg/joblib/pool.py\", line 362, in get\n",
      "    return recv()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/connection.py\", line 251, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/compile/function_module.py\", line 1082, in _constructor_Function\n",
      "    f = maker.create(input_storage, trustme=True)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/compile/function_module.py\", line 1715, in create\n",
      "    input_storage=input_storage_lists, storage_map=storage_map)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/link.py\", line 699, in make_thunk\n",
      "    storage_map=storage_map)[:3]\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/vm.py\", line 1084, in make_all\n",
      "    impl=impl))\n",
      "TypeError: ('The following error happened while compiling the node', Elemwise{Composite{((i0 * i1) + i2)}}(Elemwise{Composite{exp((i0 * clip(i1, i2, i3)))}}[(0, 1)].0, Elemwise{sqr,no_inplace}.0, TensorConstant{[[1.e-06 0..0 1.e-06]]}), '\\n', 'The numpy.ndarray object is not aligned. Theano C code does not support that.', 'object buffer<memory at 0x7f94e993f2d0>', 'object shape', (675, 675), 'object strides', (5400, 8), 'object dtype', dtype('float64'))\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/op.py\", line 833, in make_c_thunk\n",
      "    e = FunctionGraph(node.inputs, node.outputs)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/fg.py\", line 137, in __init__\n",
      "    inputs, outputs = graph.clone(inputs, outputs)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/graph.py\", line 862, in clone\n",
      "    equiv = clone_get_equiv(i, o, copy_inputs, copy_orphans)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/graph.py\", line 899, in clone_get_equiv\n",
      "    cpy = input.clone()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/graph.py\", line 607, in clone\n",
      "    cp = self.__class__(self.type, self.data, self.name)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/tensor/var.py\", line 961, in __init__\n",
      "    Constant.__init__(self, type, data, name)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/graph.py\", line 579, in __init__\n",
      "    self.data = type.filter(data)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/tensor/type.py\", line 189, in filter\n",
      "    \"object dtype\", data.dtype)\n",
      "Process ForkPoolWorker-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/joblib-0.11-py3.6.egg/joblib/pool.py\", line 362, in get\n",
      "    return recv()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/connection.py\", line 251, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/compile/function_module.py\", line 1082, in _constructor_Function\n",
      "    f = maker.create(input_storage, trustme=True)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/compile/function_module.py\", line 1715, in create\n",
      "    input_storage=input_storage_lists, storage_map=storage_map)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/link.py\", line 699, in make_thunk\n",
      "    storage_map=storage_map)[:3]\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/vm.py\", line 1084, in make_all\n",
      "    impl=impl))\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/op.py\", line 833, in make_c_thunk\n",
      "    e = FunctionGraph(node.inputs, node.outputs)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/fg.py\", line 137, in __init__\n",
      "    inputs, outputs = graph.clone(inputs, outputs)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/graph.py\", line 862, in clone\n",
      "    equiv = clone_get_equiv(i, o, copy_inputs, copy_orphans)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/graph.py\", line 899, in clone_get_equiv\n",
      "    cpy = input.clone()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/graph.py\", line 607, in clone\n",
      "    cp = self.__class__(self.type, self.data, self.name)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/tensor/var.py\", line 961, in __init__\n",
      "    Constant.__init__(self, type, data, name)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/graph.py\", line 579, in __init__\n",
      "    self.data = type.filter(data)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/tensor/type.py\", line 189, in filter\n",
      "    \"object dtype\", data.dtype)\n",
      "TypeError: ('The following error happened while compiling the node', Elemwise{Composite{((i0 * i1) + i2)}}(Elemwise{Composite{exp((i0 * clip(i1, i2, i3)))}}[(0, 1)].0, Elemwise{sqr,no_inplace}.0, TensorConstant{[[1.e-06 0..0 1.e-06]]}), '\\n', 'The numpy.ndarray object is not aligned. Theano C code does not support that.', 'object buffer<memory at 0x7f94e993f2d0>', 'object shape', (675, 675), 'object strides', (5400, 8), 'object dtype', dtype('float64'))\n",
      "Process ForkPoolWorker-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/joblib-0.11-py3.6.egg/joblib/pool.py\", line 362, in get\n",
      "    return recv()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/connection.py\", line 251, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/compile/function_module.py\", line 1082, in _constructor_Function\n",
      "    f = maker.create(input_storage, trustme=True)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/compile/function_module.py\", line 1715, in create\n",
      "    input_storage=input_storage_lists, storage_map=storage_map)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/link.py\", line 699, in make_thunk\n",
      "    storage_map=storage_map)[:3]\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/vm.py\", line 1084, in make_all\n",
      "    impl=impl))\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/op.py\", line 833, in make_c_thunk\n",
      "    e = FunctionGraph(node.inputs, node.outputs)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/fg.py\", line 137, in __init__\n",
      "    inputs, outputs = graph.clone(inputs, outputs)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/graph.py\", line 862, in clone\n",
      "    equiv = clone_get_equiv(i, o, copy_inputs, copy_orphans)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/graph.py\", line 899, in clone_get_equiv\n",
      "    cpy = input.clone()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/graph.py\", line 607, in clone\n",
      "    cp = self.__class__(self.type, self.data, self.name)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/tensor/var.py\", line 961, in __init__\n",
      "    Constant.__init__(self, type, data, name)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/gof/graph.py\", line 579, in __init__\n",
      "    self.data = type.filter(data)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/theano/tensor/type.py\", line 189, in filter\n",
      "    \"object dtype\", data.dtype)\n",
      "TypeError: ('The following error happened while compiling the node', Elemwise{Composite{((i0 * i1) + i2)}}(Elemwise{Composite{exp((i0 * clip(i1, i2, i3)))}}[(0, 1)].0, Elemwise{sqr,no_inplace}.0, TensorConstant{[[1.e-06 0..0 1.e-06]]}), '\\n', 'The numpy.ndarray object is not aligned. Theano C code does not support that.', 'object buffer<memory at 0x7f94e993f2d0>', 'object shape', (675, 675), 'object strides', (5400, 8), 'object dtype', dtype('float64'))\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/joblib-0.11-py3.6.egg/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/joblib-0.11-py3.6.egg/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/joblib-0.11-py3.6.egg/joblib/pool.py\", line 362, in get\n",
      "    return recv()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/joblib-0.11-py3.6.egg/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f2af1750b415>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHalfNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sigma_D'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mvM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVonMises\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'likelihood'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkappa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_mmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/pymc3-3.3-py3.6.egg/pymc3/sampling.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, njobs, tune, nuts_kwargs, step_kwargs, progressbar, model, random_seed, live_plot, discard_tuned_samples, live_plot_kwargs, compute_convergence_checks, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0m_print_step_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mp_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not pickle model, sampling singlethreaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/pymc3-3.3-py3.6.egg/pymc3/sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m     jobs = (delayed(_sample)(*args, **kwargs)\n\u001b[1;32m    949\u001b[0m             for args in zip(chain_nums, pbars, rseed, start))\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0mtraces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnjobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mMultiTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/joblib-0.11-py3.6.egg/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/site-packages/joblib-0.11-py3.6.egg/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/lofar1/data1/albert/miniconda3/envs/kerastf/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    tec_scale = 0.005\n",
    "    X_ = tt.constant(X.copy())\n",
    "    Y_ = tt.constant(Y.copy())\n",
    "    X_freqs_ = tt.constant(X_freqs.copy())\n",
    "    sigma = pm.Exponential('sigma',1.)\n",
    "    ls = pm.Uniform('ls',0.,2.,shape=3)\n",
    "    cov_func = sigma**2 * pm.gp.cov.ExpQuad(input_dim=3, ls=ls)\n",
    "    mean_func = pm.gp.mean.Zero()\n",
    "    gp = pm.gp.Latent(mean_func, cov_func)\n",
    "    f = -tec_scale*8.448e9*gp.prior('f',X)/X_freqs_\n",
    "    sigma = pm.HalfNormal('sigma_D',0.25*np.pi)\n",
    "    vM = pm.VonMises('likelihood',mu=f, kappa=1./sigma**2,observed=Y_)\n",
    "    trace = pm.sample(1000,use_mmap=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make wrapped phase model homoscedastic GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from gpflow import likelihoods\n",
    "from gpflow import settings\n",
    "\n",
    "from gpflow.conditionals import base_conditional\n",
    "from gpflow.params import DataHolder\n",
    "from gpflow.decors import params_as_tensors\n",
    "from gpflow.decors import name_scope\n",
    "from gpflow.logdensities import multivariate_normal\n",
    "\n",
    "from gpflow.models.model import GPModel\n",
    "\n",
    "try:\n",
    "    @tf.RegisterGradient('WrapGrad')\n",
    "    def _wrap_grad(op,grad):\n",
    "        phi = op.inputs[0]\n",
    "        return tf.ones_like(phi)*grad\n",
    "\n",
    "    def wrap(phi):\n",
    "        out = tf.atan2(tf.sin(phi),tf.cos(phi))\n",
    "        with tf.get_default_graph().gradient_override_map({'Identity': 'WrapGrad'}):\n",
    "            return tf.identity(out)\n",
    "\n",
    "except:\n",
    "    pass#already defined\n",
    "\n",
    "class WrappedGPR(GPModel):\n",
    "    \"\"\"\n",
    "    Gaussian Process Regression.\n",
    "    This is a vanilla implementation of GP regression with a Gaussian\n",
    "    likelihood.  Multiple columns of Y are treated independently.\n",
    "    The log likelihood i this models is sometimes referred to as the 'marginal log likelihood', and is given by\n",
    "    .. math::\n",
    "       \\\\log p(\\\\mathbf y \\\\,|\\\\, \\\\mathbf f) = \\\\mathcal N\\\\left(\\\\mathbf y\\,|\\, 0, \\\\mathbf K + \\\\sigma_n \\\\mathbf I\\\\right)\n",
    "    \"\"\"\n",
    "    def __init__(self, X, Y, Y_freqs, kern, mean_function=None, **kwargs):\n",
    "        \"\"\"\n",
    "        X is a data matrix, size N x D\n",
    "        Y is a data matrix, size N x R\n",
    "        kern, mean_function are appropriate GPflow objects\n",
    "        \"\"\"\n",
    "        likelihood = likelihoods.Gaussian()\n",
    "        X = DataHolder(X)\n",
    "        Y = DataHolder(Y)\n",
    "        GPModel.__init__(self, X, Y, kern, likelihood, mean_function, **kwargs)\n",
    "        self.Y_freqs = DataHolder(Y_freqs)\n",
    "\n",
    "    @name_scope('likelihood')\n",
    "    @params_as_tensors\n",
    "    def _build_likelihood(self):\n",
    "        \"\"\"\n",
    "        Construct a tensorflow function to compute the likelihood.\n",
    "            \\log p(Y | theta).\n",
    "        \"\"\"\n",
    "        K = self.kern.K(self.X) + tf.eye(tf.shape(self.X)[0], dtype=settings.float_type) * self.likelihood.variance\n",
    "        L = tf.cholesky(K)\n",
    "        m = self.mean_function(self.X)\n",
    "        logpdf = multivariate_normal(wrap(wrap(self.Y) - wrap(m)), 0.*m, L)  # (R,) log-likelihoods for each independent dimension of Y\n",
    "\n",
    "        return tf.reduce_sum(logpdf)\n",
    "\n",
    "    @name_scope('predict')\n",
    "    @params_as_tensors\n",
    "    def _build_predict(self, Xnew, full_cov=False):\n",
    "        \"\"\"\n",
    "        Xnew is a data matrix, point at which we want to predict\n",
    "        This method computes\n",
    "            p(F* | Y )\n",
    "        where F* are points on the GP at Xnew, Y are noisy observations at X.\n",
    "        \"\"\"\n",
    "        y = self.Y - self.mean_function(self.X)\n",
    "        Kmn = self.kern.K(self.X, Xnew)\n",
    "        Kmm_sigma = self.kern.K(self.X) + tf.eye(tf.shape(self.X)[0], dtype=settings.float_type) * self.likelihood.variance\n",
    "        Knn = self.kern.K(Xnew) if full_cov else self.kern.Kdiag(Xnew)\n",
    "        f_mean, f_var = base_conditional(Kmn, Kmm_sigma, Knn, y, full_cov=full_cov, white=False)  # N x P, N x P or P x N x N\n",
    "        return f_mean + self.mean_function(Xnew), f_var"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
