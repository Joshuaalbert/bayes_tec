{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/albert/miniconda3/envs/tectf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "from timeit import default_timer\n",
    "from collections import namedtuple\n",
    "import pylab as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import gpflow as gp\n",
    "\n",
    "import astropy.coordinates as ac\n",
    "import astropy.time as at\n",
    "import astropy.units as au\n",
    "\n",
    "from scipy.cluster.vq import kmeans2\n",
    "\n",
    "from bayes_tec.frames import ENU\n",
    "from bayes_tec.datapack import DataPack\n",
    "from bayes_tec.utils.data_utils import make_coord_array, calculate_weights\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "float_type = tf.float64\n",
    "jitter = 1e-6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpflow.transforms import Identity\n",
    "\n",
    "class Parameter(object):\n",
    "    def __init__(self, name, value, transform=Identity(), prior=None,\n",
    "                 trainable=True, dtype=float_type, unconstrained_tensor=None):\n",
    "        self.name = name\n",
    "        self.prior = prior          # pylint: disable=W0201\n",
    "        self.transform = transform  # pylint: disable=W0201\n",
    "        if unconstrained_tensor is None:\n",
    "            self._initial_value_tensor = tf.convert_to_tensor(value,dtype=dtype)\n",
    "            self._unconstrained_tensor_ref = tf.get_variable(name, dtype=dtype, \n",
    "                    initializer=self.transform.backward_tensor(self._initial_value_tensor), \n",
    "                    trainable=trainable,\n",
    "                    use_resource=True)\n",
    "            self._unconstrained_tensor = tf.identity(self.unconstrained_tensor_ref)\n",
    "        else:\n",
    "            self._unconstrained_tensor_ref = None\n",
    "            self._unconstrained_tensor = unconstrained_tensor\n",
    "            self._initial_value_tensor = self.transform.forward_tensor(unconstrained_tensor)\n",
    "        self._constrained_tensor = self.transform.forward_tensor(self.unconstrained_tensor)\n",
    "        self._prior_tensor = self._build_prior(self.unconstrained_tensor, self.constrained_tensor)\n",
    "\n",
    "    @property\n",
    "    def unconstrained_tensor_ref(self):\n",
    "        return self._unconstrained_tensor_ref\n",
    "    \n",
    "    @property\n",
    "    def unconstrained_tensor(self):\n",
    "        return self._unconstrained_tensor\n",
    "\n",
    "    @property\n",
    "    def constrained_tensor(self):\n",
    "        return self._constrained_tensor\n",
    "\n",
    "    @property\n",
    "    def prior_tensor(self):\n",
    "        \"\"\"log P(constrained_param) + log |det transform(unconstrained_param)|\"\"\"\n",
    "        return self._prior_tensor\n",
    "  \n",
    "    @property\n",
    "    def initializer(self):\n",
    "        if self.unconstrained_tensor_ref is None:\n",
    "            raise ValueError(\"No variable referenced\")\n",
    "        return self.unconstrained_tensor_ref.initializer\n",
    "\n",
    "    def assign_op(self, value):\n",
    "        if self.unconstrained_tensor_ref is None:\n",
    "            raise ValueError(\"No variable referenced\")\n",
    "        return tf.assign(self._unconstrained_tensor_ref,self.transform.backward_tensor(value))\n",
    "        \n",
    "    def _build_prior(self, unconstrained_tensor, constrained_tensor):\n",
    "        prior_name = '{}_logp'.format(self.name)\n",
    "\n",
    "        if self.prior is None:\n",
    "            logp_param = tf.constant(0.0, float_type)\n",
    "        else:\n",
    "            logp_param = self.prior(constrained_tensor)\n",
    "\n",
    "        log_jacobian = self.transform.log_jacobian_tensor(unconstrained_tensor)\n",
    "        \n",
    "        return tf.squeeze(tf.add(logp_param, log_jacobian, name=prior_name))\n",
    "    \n",
    "class Kernel(object):\n",
    "    def __init__(self, time_lengthscale, dir_lengthscale, ant_lengthscale, dot_var, dot_offset,\n",
    "                active_dims_time=None,active_dims_dir=None,active_dims_ant=None):\n",
    "        self.dir_lengthscale = dir_lengthscale\n",
    "        self.time_lengthscale = time_lengthscale\n",
    "        self.ant_lengthscale = ant_lengthscale\n",
    "        self.dot_var = dot_var\n",
    "        self.dot_offset = dot_offset\n",
    "        self.active_dims_time = active_dims_time or slice(0,1,1)\n",
    "        self.active_dims_dir = active_dims_dir or slice(1,3,1)\n",
    "        self.active_dims_ant = active_dims_ant or slice(3,5,1)\n",
    "        \n",
    "    def scaled_square_dist_batched(self,X, X2, lengthscale):\n",
    "        \"\"\"\n",
    "        X: tensor B, N, D\n",
    "        X2: tensor B, M, D (or 1, M, D) and will be broadcast to B, M ,D\n",
    "        Return:\n",
    "        tensor B, N, M\n",
    "        \"\"\"\n",
    "        # Clipping around the (single) float precision which is ~1e-45.\n",
    "        X = X / lengthscale\n",
    "        Xs = tf.reduce_sum(tf.square(X), axis=2)#B,N\n",
    "\n",
    "        if X2 is None:\n",
    "            dist = -2.*tf.matmul(X,X,transpose_b=True)\n",
    "            dist += Xs[:,:,None] + Xs[:,None,:]\n",
    "            return tf.maximum(dist, 1e-40)\n",
    "\n",
    "        # B (1), M, D\n",
    "        X2 = X2 / lengthscale\n",
    "        X2s = tf.reduce_sum(tf.square(X2), axis=2)# B (1), M \n",
    "        dist = -2 * tf.matmul(X, X2, transpose_b=True)\n",
    "        dist += Xs[:,:,None] + X2s[:,None,:]\n",
    "        return dist\n",
    "    \n",
    "    def scaled_square_dist(self,X, X2, lengthscale):\n",
    "        \"\"\"\n",
    "        X: tensor N, D\n",
    "        X2: tensor M, D\n",
    "        Return:\n",
    "        tensor N, M\n",
    "        \"\"\"\n",
    "        # Clipping around the (single) float precision which is ~1e-45.\n",
    "        X = X / lengthscale\n",
    "        Xs = tf.reduce_sum(tf.square(X), axis=1)#N\n",
    "\n",
    "        if X2 is None:\n",
    "            dist = -2.*tf.matmul(X,X,transpose_b=True)\n",
    "            dist += Xs[:,None] + Xs[None,:]\n",
    "            return tf.maximum(dist, 1e-40)\n",
    "\n",
    "        # M, D\n",
    "        X2 = X2 / lengthscale\n",
    "        X2s = tf.reduce_sum(tf.square(X2), axis=1)#  M \n",
    "        dist = -2 * tf.matmul(X, X2, transpose_b=True)\n",
    "        dist += Xs[:,None] + X2s[None,:]\n",
    "        return dist\n",
    "    \n",
    "    def _clipped_sqrt(self, r2):\n",
    "        # Clipping around the (single) float precision which is ~1e-45.\n",
    "        return tf.sqrt(tf.maximum(r2, 1e-40))\n",
    "\n",
    "    \n",
    "    def K(self, X, X2=None):\n",
    "        \"\"\"Returns the covariance at X and X2.\n",
    "        (dot_offset + dot_var*X.X2) * M52(time) * RBF(dir) * M12(ant)\n",
    "        Args:\n",
    "        :param X: float Tensor [N, ndims]\n",
    "        :param X2: float Tensor [M, ndims]\n",
    "        Returns:\n",
    "        float Tensor [N,M]\n",
    "        \"\"\"\n",
    "        Xt = X[:,self.active_dims_time]\n",
    "        Xd = X[:,self.active_dims_dir]\n",
    "        Xa = X[:,self.active_dims_ant]\n",
    "        \n",
    "        if X2 is None:\n",
    "            X2t = None\n",
    "            X2d = None\n",
    "            X2a = None\n",
    "        else:\n",
    "            X2t = X2[:,self.active_dims_time]\n",
    "            X2d = X2[:,self.active_dims_dir]\n",
    "            X2a = X2[:,self.active_dims_ant]\n",
    "        \n",
    "        \n",
    "        r2t = self.scaled_square_dist(Xt, X2t, self.time_lengthscale)\n",
    "        rt = self._clipped_sqrt(r2t)\n",
    "        r2d = self.scaled_square_dist(Xd, X2d, self.dir_lengthscale)\n",
    "        ra = self._clipped_sqrt(self.scaled_square_dist(Xa, X2a, self.ant_lengthscale))\n",
    "        \n",
    "        combined_exp = tf.accumulate_n([np.sqrt(5.)*rt, 0.5*r2d, ra])\n",
    "        combined_exp = tf.exp(-combined_exp)\n",
    "        dot_kern = self.dot_offset + self.dot_var * tf.matmul(Xd, Xd if X2d is None else X2d, transpose_b=True)\n",
    "        time_m52 = (1. + np.sqrt(5.) * rt + (5./3.) * r2t)\n",
    "        \n",
    "        return combined_exp*dot_kern*time_m52\n",
    "    \n",
    "    def Kdiag(self, X):\n",
    "        \"\"\"Returns the diag of the covariance at X.\n",
    "        Args:\n",
    "        :param X: float Tensor [N, ndims]\n",
    "        Returns:\n",
    "        float Tensor [N]\n",
    "        \"\"\"\n",
    "        return self.dot_var*tf.linalg.norm(X,axis=-1,keepdims=False) + self.dot_offset\n",
    "\n",
    "def make_solsets(datapack,output_solset, screen_res=15, extend = 0., solset='sol000'):\n",
    "    screen_solset = \"screen_{}\".format(output_solset)\n",
    "    \n",
    "    datapack.switch_solset(solset)\n",
    "    datapack.select(ant=None,time=None, dir=None, freq=None, pol=slice(0,1,1))\n",
    "    axes = datapack.__getattr__(\"axes_{}\".format('phase'))\n",
    "\n",
    "    antenna_labels, antennas = datapack.get_antennas(axes['ant'])\n",
    "    patch_names, directions = datapack.get_sources(axes['dir'])\n",
    "    timestamps, times = datapack.get_times(axes['time'])\n",
    "    freq_labels, freqs = datapack.get_freqs(axes['freq'])\n",
    "    pol_labels, pols = datapack.get_pols(axes['pol'])\n",
    "\n",
    "    Npol, Nd, Na, Nf, Nt = len(pols), len(directions), len(antennas), len(freqs), len(times)\n",
    "    \n",
    "#     screen_directions = dialated_faceted(directions.ra.rad.mean(), directions.dec.rad.mean(),\n",
    "#                                         N=screen_res)\n",
    "\n",
    "    screen_ra = np.linspace(np.min(directions.ra.rad) - extend*np.pi/180., \n",
    "            np.max(directions.ra.rad) + extend*np.pi/180., screen_res)\n",
    "    screen_dec = np.linspace(max(-90.*np.pi/180.,np.min(directions.dec.rad) - extend*np.pi/180.), \n",
    "            min(90.*np.pi/180.,np.max(directions.dec.rad) + extend*np.pi/180.), screen_res)\n",
    "    screen_directions = np.stack([m.flatten() \\\n",
    "            for m in np.meshgrid(screen_ra, screen_dec, indexing='ij')], axis=1)\n",
    "    screen_directions = ac.SkyCoord(screen_directions[:,0]*au.rad,screen_directions[:,1]*au.rad,frame='icrs')\n",
    "    Nd_screen = screen_res**2\n",
    "\n",
    "    datapack.switch_solset(output_solset, \n",
    "            array_file=DataPack.lofar_array, \n",
    "            directions = np.stack([directions.ra.rad,directions.dec.rad],axis=1), patch_names=patch_names)\n",
    "    datapack.add_freq_indep_tab('tec', times.mjd*86400., pols = pol_labels)   \n",
    "    datapack.add_freq_dep_tab('amplitude', times.mjd*86400., pols = pol_labels,freqs=freqs)\n",
    "    datapack.add_freq_dep_tab('phase', times.mjd*86400., pols = pol_labels,freqs=freqs)\n",
    "\n",
    "\n",
    "    datapack.switch_solset(screen_solset, \n",
    "            array_file = DataPack.lofar_array, \n",
    "            directions = np.stack([screen_directions.ra.rad,screen_directions.dec.rad],axis=1))\n",
    "    datapack.add_freq_indep_tab('tec', times.mjd*86400., pols = pol_labels)\n",
    "    datapack.add_freq_dep_tab('amplitude', times.mjd*86400., pols = pol_labels,freqs=freqs)\n",
    "    datapack.add_freq_dep_tab('phase', times.mjd*86400., pols = pol_labels,freqs=freqs)\n",
    "\n",
    "    datapack.switch_solset(solset)\n",
    "    \n",
    "def get_solset_coords(datapack,solset):\n",
    "    datapack.switch_solset(solset)\n",
    "    axes = datapack.axes_phase\n",
    "    antenna_labels, antennas = datapack.get_antennas(axes['ant'])\n",
    "    patch_names, directions = datapack.get_sources(axes['dir'])\n",
    "    timestamps, times = datapack.get_times(axes['time'])\n",
    "    pol_labels, pols = datapack.get_pols(axes['pol'])\n",
    "    \n",
    "    antennas_enu = antennas.transform_to(ENU(obstime=times[0],location=datapack.array_center))\n",
    "    X_a = np.array([antennas_enu.east.value,\n",
    "                    antennas_enu.north.value]).T/1000.\n",
    "    X_d = np.array([directions.ra.deg - directions.ra.deg.mean(), directions.dec.deg - directions.dec.deg.mean()]).T\n",
    "    X_t = (times.mjd*86400 - times[0].mjd*86400.)[:,None]\n",
    "    \n",
    "    return X_t, X_d, X_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UpdateResult = namedtuple('UpdateResult',['x_samples','z_samples','log_prob', 'acceptance','step_size'])\n",
    "\n",
    "class TargetDistribution(object):\n",
    "    def __init__(self, \n",
    "                 kerns, \n",
    "                 z_tm1, \n",
    "                 X_t, \n",
    "                 X_tm1, \n",
    "                 Y_t, \n",
    "                 freqs, \n",
    "                 L_tm1, \n",
    "                 num_chains,\n",
    "                 max_lik=True, \n",
    "                 step_size=0.01,\n",
    "                 Y_sigma=1.,\n",
    "                 approximate_posterior = 'mfsg',\n",
    "                 prior_opts = {}):\n",
    "        \"\"\"\n",
    "        The target distribution of the Bayes filter.\n",
    "        Args:\n",
    "        :param z_tm1: float Tensor [S, num_chains, M, Np]\n",
    "        :param X: float Tensor [N,K]\n",
    "        :param last_X: float Tensor [Np, K]\n",
    "        :param Y: float Tensor [D, N, Nf]\n",
    "        :param Y_std: float Tensor [D, N, Nf]\n",
    "        :param freqs: float Tensor [Nf]\n",
    "        :param L11: float Tensor [M, Np, Np]\n",
    "        \"\"\"\n",
    "        self.M = tf.shape(z_tm1)[2]\n",
    "        self.S = tf.shape(z_tm1)[0]\n",
    "        self.num_chains = num_chains\n",
    "        self.N = tf.shape(Y_t)[1]\n",
    "        self.Np = tf.shape(z_tm1)[-1]\n",
    "        \n",
    "        #M, N, N\n",
    "        self.Kx_t = kerns[0](X_t)\n",
    "        #M, N, N\n",
    "        self.Kh_t = kerns[1](X_t)\n",
    "        #M, Np, Np\n",
    "        self.Kx_tm1 = kerns[0](X_tm1)\n",
    "        #M, Np, Np\n",
    "        self.Kh_tm1 = kerns[1](X_tm1)\n",
    "        self.jitter = tf.convert_to_tensor(jitter,dtype=float_type,name='jitter')\n",
    "        \n",
    "        self.offset_t = self.jitter*tf.eye(self.N,dtype=float_type)\n",
    "        self.offset_tm1 = self.jitter*tf.eye(self.Np,dtype=float_type)\n",
    "        #M, N, N\n",
    "        self.Lx_t = tf.cholesky(self.Kx_t + self.offset_t)\n",
    "        #M, N, N\n",
    "        self.Lh_t = tf.cholesky(self.Kh_t + self.offset_t)\n",
    "        #M, Np, Np\n",
    "        self.Lx_tm1 = tf.cholesky(self.Kx_tm1 + self.offset_tm1)\n",
    "        #M, Np, Np\n",
    "        self.Lh_tm1 = tf.cholesky(self.Kh_tm1 + self.offset_tm1)\n",
    "        \n",
    "        #M, Np, N\n",
    "        self.Kx_tm1t = kern(X_tm1, X_t)\n",
    "        #S, num_chains, M, N\n",
    "        self.z_tm1 = z_tm1\n",
    "        #D, N, Nf\n",
    "        self.Y = Y\n",
    "        #Nf\n",
    "        self.freqs = freqs\n",
    "        \n",
    "        self.step_size = tf.get_variable(\n",
    "                name='step_size',\n",
    "                initializer=lambda: tf.constant(step_size,dtype=tf.float64),\n",
    "                use_resource=True,\n",
    "                dtype=tf.float64,\n",
    "                trainable=False)\n",
    "        \n",
    "        self.Y_sigma = Y_sigma\n",
    "        self.max_lik = max_lik\n",
    "        self.approximate_posterior = approximate_posterior\n",
    "        self.prior_opts = prior_opts\n",
    "        \n",
    "    def likelihood(self, x_t):\n",
    "        \"\"\"\n",
    "        Calculate the likelihood of Y given hidden_state.\n",
    "        I.e.\n",
    "            sum_i log[P(Y_j(X_i) | X_i)]\n",
    "        If Y_j in C^Nf and assuming independence between \n",
    "        real, imag, and components we get,\n",
    "            sum_i sum_j log[P(Re[Y_j(X_i)] | X_i)] \n",
    "                        + log[P(imag[Y_j(X_i)] | X_i)]\n",
    "        Args:\n",
    "        :param x_t: float Tensor [num_chains, M, N+H]\n",
    "        Returns:\n",
    "        float Tensor [num_chains]\n",
    "        \"\"\"\n",
    "        #num_chains, N\n",
    "        x_t = x_t[:, 0, :self.N]\n",
    "        #Nf\n",
    "        tec_conv = tf.div(tf.cast(-8.448e6,tf.float64),self.freqs,name='tec_conv')\n",
    "        #num_chains, N, Nf\n",
    "        phi = tec_conv*x_t[:,:,None]\n",
    "        g_real = tf.cos(phi)\n",
    "        g_imag = tf.sin(phi)\n",
    "        #D, num_chains, N, Nf\n",
    "        g = tf.stack([g_real, g_imag],axis=0,name='g')\n",
    "        L = tfp.distributions.MultivariateNormalDiag(loc=g, scale_identity_multiplier = self.sigma_amp,#scale_diag=self.sigma_amp*self.Y_std[:, None,:,:]\n",
    "                                                     name='data_likelihood')        \n",
    "        #D,num_chains, N\n",
    "        logp = L.log_prob(self.Y[:,None,:,:])\n",
    "        #num_chains\n",
    "        return tf.reduce_sum(logp,axis=[0, 2])\n",
    "\n",
    "    def _mfsg_logp(self,x_t,**prior_opts):\n",
    "        '''\n",
    "        Evaluates log probability of the predict step assuming\n",
    "        a the mean field single Gaussian (MF) representing the \n",
    "        resulting mixture of Gaussians as a single Gaussian.\n",
    "        It is less correct than the (MF) approximation\n",
    "        but has complexity O(SM^2 + M^3).\n",
    "        Args:\n",
    "        :param x_t: float Tensor [num_chains, M, N]\n",
    "        Returns:\n",
    "        float Tensor [num_chains]\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def _mf_logp(self,x_t, num_sigma_points = 10,**prior_opts):\n",
    "        '''\n",
    "        Evaluates log probability of the predict step assuming\n",
    "        a the mean field approximation (MF). It is the most correct\n",
    "        approximation but also the highest complexity O(SM^3).\n",
    "        Args:\n",
    "        :param x_t: float Tensor [num_chains, M, N]\n",
    "        Returns:\n",
    "        float Tensor [num_chains]\n",
    "        '''\n",
    "        num_sigma_points = tf.convert_to_tensor(num_sigma_points, dtype=tf.int32)\n",
    "\n",
    "        s = tf.minimum(num_sigma_points, tf.shape(self.z_tm1)[0])\n",
    "        shuffle_index = tf.random_shuffle(tf.range(tf.shape(self.z_tm1)[0],dtype=tf.int32))[:s]\n",
    "        #s, num_chains, M, Np\n",
    "        z_tm1 = tf.gather(self.z_tm1, shuffle_index, axis=0,name='z_tm1')\n",
    "        x_tm1 = tf.einsum('mij,snmj->snmi',self.L11, z_tm1)\n",
    "\n",
    "        # log[P(Z_i | Z_i-1,s)] = log[N[m_i, C]] + log\n",
    "        #M, Np, N\n",
    "        A = tf.matrix_triangular_solve(self.L11,self.K10)\n",
    "#         #s, num_chains, M, Np, N\n",
    "#         A_expand = tf.tile(A[None, None, :, :, :], [s, self.num_chains,1,1,1])\n",
    "#         #s, num_chains, M, N\n",
    "#         m = tf.matmul(A_expand, z_tm1[:,:,:,:,None],transpose_a=True)[:,:,:,:,0]\n",
    "        #s, num_chains, M, N\n",
    "        m = tf.einsum('mij,snmi->snmj',A,x_tm1)\n",
    "        #M, N, N\n",
    "        C = self.K00 - tf.matmul(A, A, transpose_a=True)\n",
    "        #M, N, N\n",
    "        L = tf.cholesky(C + tf.cast(jitter,tf.float64)*tf.eye(tf.shape(C)[2],dtype=tf.float64))\n",
    "        P = tfp.distributions.MultivariateNormalTriL(loc=m, scale_tril=L[None, None,:,:,:])\n",
    "        #s, num_chains, M\n",
    "        log_prob = P.log_prob(x_t) - tf.reduce_sum(tf.log(tf.matrix_diag_part(self.L00)),axis=1)\n",
    "        #s, num_chains\n",
    "        log_prob = tf.reduce_sum(log_prob, axis=2)\n",
    "        #num_chains\n",
    "        log_prob = tf.reduce_logsumexp(log_prob,axis=0) - tf.log(tf.cast(s,tf.float64))\n",
    "        log_prob.set_shape(tf.TensorShape([self.num_chains]))\n",
    "        return log_prob\n",
    "    \n",
    "    def _gpp_logp(self,x_t,**prior_opts):\n",
    "        '''\n",
    "        Evaluates log probability of the predict step assuming\n",
    "        a Gaussian previous posterior (GPP) and conditional \n",
    "        independence of the hyperparameters. In this case, \n",
    "        marginalisation is analytic.\n",
    "        Args:\n",
    "        :param x_t: float Tensor [num_chains, M, N]\n",
    "        Returns:\n",
    "        float Tensor [num_chains]\n",
    "        '''\n",
    "        #S, num_chains, M, Np,1\n",
    "        x_tm1 = tf.einsum('mij,snmj->snmi',self.L11, self.z_tm1)[..., None]\n",
    "        #num_chains, M, Np,1\n",
    "        m_tm1 = tf.reduce_mean(x_tm1,axis=0)\n",
    "        #num_chains, M, Np,Np\n",
    "        m2 = tf.matmul(m_tm1,m_tm1, transpose_b=True)\n",
    "        #num_chains, M, Np, Np\n",
    "        C_tm1 = tf.reduce_mean(tf.matmul(x_tm1, x_tm1,transpose_b=True), axis=0) - m2\n",
    "            \n",
    "    \n",
    "    def prior_logp(self, x_t):\n",
    "        \"\"\"\n",
    "        Calculate the predict step, i.e.\n",
    "            log[P(X_i | Y_i-1)] = log E_i-1[P(X_i | X_i-1)]\n",
    "                                = log sum_s P(X_i | X_i-1,s) - log S\n",
    "                                = logsumexp_s log[P(X_i | X_i-1,s)] - log S\n",
    "            If we transform the variables through,\n",
    "            X = L.Z + m => log P(X) = log P(Z) - log det L\n",
    "            log[P(X_i | X_i-1,s)] = log[P(Z_i | Z_i-1,s)] - log det L_i\n",
    "        Assumes hidden state is a GP marginal.\n",
    "        Args:\n",
    "        :param x_t: float Tensor [num_chains, M, N]\n",
    "        Returns:\n",
    "        [num_chains]\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.approximate_posterior == 'mfsg':\n",
    "            log_prob = self._mfsg_logp(x_t, **self.prior_opts)\n",
    "        elif self.approximate_posterior == 'mf':\n",
    "            log_prob = self._mf_logp(x_t,**self.prior_opts)\n",
    "        elif self.approximate_posterior == 'gpp':\n",
    "            log_prob = self._gpp_logp(x_t,**self.prior_opts)\n",
    "            \n",
    "        log_prob.set_shape(tf.TensorShape([self.num_chains]))\n",
    "        return log_prob\n",
    "    \n",
    "    def unnormalized_logp(self,z_t):\n",
    "        \"\"\"\n",
    "        Returns the unnormalized probability density of the Bayes filter posterior.\n",
    "        log P(y_t | z_t) + log (1/S) sum_s P(z_t | z^s_t-1)\n",
    "        Args:\n",
    "        :param z_t: float Tensor [num_chains, M*(N+H)]\n",
    "        Returns:\n",
    "        [num_chains]\n",
    "        \"\"\"\n",
    "        #num_chains, M, N+H\n",
    "        z_t = tf.cast(tf.reshape(z_t,[self.num_chains, self.M, -1]),tf.float64)\n",
    "        #num_chains, M, N+H\n",
    "        x_t = tf.einsum('mij,nmj->nmi', self.L00, z_t)\n",
    "        \n",
    "#         #num_chains, M, N, N\n",
    "#         L00_expand = tf.tile(self.L00[None, :, :self.N, :self.N], [self.num_chains, 1,1,1])\n",
    "#         #num_chains, N\n",
    "#         x_t = tf.matmul(L00_expand, z_t[:, :, :self.N, None])[:, 0, :, 0]\n",
    "\n",
    "        #num_chains, N\n",
    "        x_t = x_t[:, 0, :self.N]\n",
    "        max_lik_logp = self.likelihood(x_t)\n",
    "        full_post_logp = max_lik_logp + self.prior_logp(x_t)\n",
    "        logp = tf.cond(self.max_lik,\n",
    "                       lambda: max_lik_logp, \n",
    "                       lambda: full_post_logp)\n",
    "        return logp#self.likelihood(x_t) + self.prior_logp(x_t)\n",
    "    \n",
    "    def sample(self,num_samples=10, step_size = 1., num_leapfrog_steps=2, target_rate=0.75):\n",
    "        \n",
    "        \n",
    "        \n",
    "        hmc = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "                        target_log_prob_fn=self.unnormalized_logp,\n",
    "                        num_leapfrog_steps=num_leapfrog_steps,#tf.random_shuffle(tf.range(3,60,dtype=tf.int64))[0],\n",
    "                        step_size=self.step_size,\n",
    "            step_size_update_fn=tfp.mcmc.make_simple_step_size_update_policy(target_rate=target_rate))\n",
    "#                         step_size_update_fn=lambda v, _: v)\n",
    "\n",
    "        #num_chains, M, Np\n",
    "        q0 = tf.reduce_mean(self.z_tm1,axis=0)\n",
    "        q0 = tf.reshape(q0,(self.num_chains, -1))\n",
    "#         q0.set_shape(tf.TensorShape([self.num_chains, None]))\n",
    "        # Run the chain (with burn-in).\n",
    "        z_samples, kernel_results = tfp.mcmc.sample_chain(\n",
    "            num_results=num_samples,\n",
    "            num_burnin_steps=0,\n",
    "            current_state=q0,\n",
    "            kernel=hmc)\n",
    "        \n",
    "        avg_acceptance_ratio = tf.reduce_mean(tf.exp(tf.minimum(kernel_results.log_accept_ratio, 0.)),name='avg_acc_ratio')\n",
    "        posterior_log_prob = tf.reduce_sum(kernel_results.accepted_results.target_log_prob,name='marginal_log_likelihood')\n",
    "        \n",
    "        z_samples = tf.reshape(z_samples, tf.concat([tf.shape(z_samples)[:2], [self.M], [-1]],axis=0))\n",
    "        x_samples = tf.einsum(\"mij,snmj->snmi\",self.L00,z_samples)\n",
    "        \n",
    "        res = UpdateResult(x_samples, z_samples, posterior_log_prob, avg_acceptance_ratio, kernel_results.extra.step_size_assign)\n",
    "        return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.89991101683914\n",
      "99.89999999987855\n",
      "0.5985713550796885 0.39545414644949545\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "a = np.random.uniform(size=10)\n",
    "A = np.random.uniform(size=10)**2\n",
    "\n",
    "p = np.random.uniform(size=10)\n",
    "p /= p.sum()\n",
    "\n",
    "m = np.sum(p*a)\n",
    "M = np.sum(p*(A + a*a - m*m))\n",
    "\n",
    "x = np.linspace(-5,5,1000)\n",
    "\n",
    "y = np.sum([pi*np.exp(-0.5*(x - ai)**2/Ai)/np.sqrt(2*np.pi*Ai) for (pi,ai,Ai) in zip(p,a,A)], axis=0)\n",
    "print(y.sum())\n",
    "# y /= y.sum()\n",
    "\n",
    "Y = np.exp(-0.5*(x-m)**2 / M)/np.sqrt(2*np.pi*M)\n",
    "print(Y.sum())\n",
    "# Y /= Y.sum()\n",
    "\n",
    "print(m,M)\n",
    "\n",
    "plt.plot(x,Y)\n",
    "plt.plot(x,y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
